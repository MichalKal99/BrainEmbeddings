{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import normalize\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: p00, session: ses1\n"
     ]
    }
   ],
   "source": [
    "channels_to_skip = ['MKR1+', 'MKR2+', 'EKG+']\n",
    "path = Path('sentences_data/sentences/')\n",
    "outPath = Path('./eeg/')\n",
    "patient_data = {}\n",
    "i=0\n",
    "\n",
    "for file in path.rglob('*sentences.xdf'):\n",
    "\n",
    "    patient_id, session_id = file.name.split(\"_\")[:2]\n",
    "    if i == 1:\n",
    "         break\n",
    "    if session_id != \"ses1\":\n",
    "         continue\n",
    "\n",
    "    print(f\"Patient ID: {patient_id}, session: {session_id}\")\n",
    "    eeg_ts = np.load(f\"sentences_data/eeg/{patient_id}_{session_id}_sentences_sEEG.npy\")\n",
    "    audio_ts = np.load(f\"sentences_data/eeg/{patient_id}_{session_id}_sentences_audio.npy\")\n",
    "    ch_names = np.load(f\"sentences_data/eeg/{patient_id}_{session_id}_sentences_channelNames.npy\")\n",
    "    sentences_ts = np.load(f\"sentences_data/eeg/{patient_id}_{session_id}_sentences.npy\")\n",
    "\n",
    "    channels_to_skip_idx = [np.where(ch==ch_names)[0][0] for ch in channels_to_skip]\n",
    "    ch_names = np.delete(ch_names, channels_to_skip_idx)\n",
    "    eeg_ts = np.delete(eeg_ts, channels_to_skip_idx, axis=1)\n",
    "    \n",
    "    patient_data[(patient_id, session_id)] = {\n",
    "         \"eeg\":eeg_ts,\n",
    "         \"audio\":audio_ts,\n",
    "         \"channels\":ch_names,\n",
    "         \"sentences\":sentences_ts\n",
    "    }\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dictionary = {}\n",
    "for k, v in patient_data.items():\n",
    "    unique_sent = np.unique(v[\"sentences\"])\n",
    "    for sent in unique_sent:\n",
    "        if sent in sent_dictionary.keys():\n",
    "            sent_dictionary[sent] += 1\n",
    "        else:\n",
    "            sent_dictionary[sent] = 1\n",
    "    patient_data[k][\"sentenceList\"] = unique_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_key, data in patient_data.items():\n",
    "    # get unique sentences \n",
    "    sentences, sentences_start_idx, sentences_ts_indexed = np.unique(data[\"sentences\"], return_index=True, return_inverse=True)\n",
    "\n",
    "    # get sentences timepoints\n",
    "    sentences_pos_dict = {i:{\"sentence\":sent, \"indicies\":[]} for i, sent in enumerate(sentences)}\n",
    "    prev_sent_key = sentences_ts_indexed[0]\n",
    "    start_pos_i = 0 \n",
    "\n",
    "    for pos_i, current_sent_key in enumerate(sentences_ts_indexed):\n",
    "        if current_sent_key != prev_sent_key:\n",
    "            idx_tuple = (start_pos_i, pos_i)\n",
    "            sentences_pos_dict[prev_sent_key][\"indicies\"].append(idx_tuple)\n",
    "            start_pos_i = pos_i\n",
    "        prev_sent_key = current_sent_key\n",
    "    \n",
    "    patient_data[patient_key][\"sentencesPositions\"] = sentences_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in sent_dictionary.items() if v > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fft, fftfreq, rfft, rfftfreq\n\u001b[1;32m----> 3\u001b[0m sentence_key \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msent_dictionary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from scipy.fft import fft, fftfreq, rfft, rfftfreq\n",
    "\n",
    "sentence_key = [(k, v) for k, v in sent_dictionary.items() if v > 2][1][0]\n",
    "\n",
    "i=0\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15,10))\n",
    "axs = axs.reshape(-1)\n",
    "for pt, pt_data in patient_data.items():\n",
    "    if sentence_key in pt_data[\"sentenceList\"]:\n",
    "        sentence_idx = np.where(pt_data[\"sentenceList\"]==sentence_key)[0][0]\n",
    "        sentence_position = pt_data[\"sentencesPositions\"][sentence_idx][\"indicies\"]\n",
    "        eeg = pt_data[\"eeg\"][sentence_position[0][0]:sentence_position[0][1],:]\n",
    "        eeg_mean = np.mean(eeg, axis=1)\n",
    "\n",
    "        yf = rfft(eeg_mean)\n",
    "        xf = rfftfreq(len(eeg_mean), 1 / 1024)\n",
    "\n",
    "        # axs[i].plot(xf, np.abs(yf))\n",
    "        axs[i].plot(eeg_mean)\n",
    "        i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_key in range(0, len(sentences))[:1]:\n",
    "    pos_tup_arr = sentences_dict[sent_key][\"indicies\"]\n",
    "    sentence_str = sentences_dict[sent_key][\"sentence\"]\n",
    "    print(f\"Sentence: {sentence_str}\")\n",
    "\n",
    "    for pos_tup in pos_tup_arr[1:2]:\n",
    "        eeg_sent_ts = eeg_ts[pos_tup[0]:pos_tup[1],40:50]\n",
    "        plt.plot(eeg_sent_ts)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512475, 107)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy \n",
    "\n",
    "scipy.stats.zscore(list(patient_data.values())[0][\"eeg\"]).shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
